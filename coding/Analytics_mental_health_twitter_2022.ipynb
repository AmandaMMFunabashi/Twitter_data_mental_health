{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b934fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c711fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('service_key.json', scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd717daa",
   "metadata": {},
   "source": [
    "# Analytics\n",
    "\n",
    "Based on twitter data scrap of mental health issues (PT-BR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab359c3c",
   "metadata": {},
   "source": [
    "-- Data is not public"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38079c3d",
   "metadata": {},
   "source": [
    "## Data from GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50820594",
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet_key = '1hMzLN_Zt5sZ5rFA3CBJ0JlNDN4XhQauMiZqQmoGONeo'\n",
    "book = gc.open_by_key(spreadsheet_key)\n",
    "worksheet = book.worksheet(\"tweets\")\n",
    "table = worksheet.get_all_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1cbc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert table data into a dataframe\n",
    "df = pd.DataFrame(table[1:], columns=table[0])\n",
    "\n",
    "##Convert number strings to floats and ints\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "##Convert date strings to datetime format\n",
    "df['created_at'] = pd.to_datetime(df['created_at'],infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64f970f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2832, 12)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77ed4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = df[df.y.notna()]\n",
    "#test = df[df.y.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06d7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b5fd20",
   "metadata": {},
   "source": [
    "## Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2a341",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3065cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a67cc468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import preprocessor as tp\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "#important libraries for preprocessing using NLTK\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('punkt')\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31907593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove accents\n",
    "df['text'] = df['text'].apply(lambda x : unidecode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9198e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ponctuations and lower case\n",
    "df['text'] = df['text'].apply(lambda x : re.sub(r'[^\\w\\s]', '', x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bd70b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deals with urls, mentions, reserved words (RT, FAV), *emojis, *smileys - [*] what im using\n",
    "df['text'] = df['text'].apply(lambda x : tp.clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22dd0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    return ' '.join([word for word in tokens if word not in stopwords.words('portuguese')])\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x : remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f7e8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "df['text'] = df['text'].apply(lambda x : tokenize.word_tokenize(x, language = 'portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cd744c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>created_at</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>entities</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1486803274338643977</td>\n",
       "      <td>[{'domain': {'id': '46', 'name': 'Business Tax...</td>\n",
       "      <td>2022-11-26 00:51:56+00:00</td>\n",
       "      <td>[1596305720626262016]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1596305720626262016</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[krlh, anime, romance, deixa, depressao, poha]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1438560931399835651</td>\n",
       "      <td></td>\n",
       "      <td>2022-11-26 00:51:52+00:00</td>\n",
       "      <td>[1596305703991271424]</td>\n",
       "      <td>{'annotations': [{'start': 0, 'end': 6, 'proba...</td>\n",
       "      <td></td>\n",
       "      <td>1596305703991271424</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[cafalho, so, depressao, nessa, desgraca, vai,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1318048828797444098</td>\n",
       "      <td></td>\n",
       "      <td>2022-11-26 00:51:52+00:00</td>\n",
       "      <td>[1596305703433809920]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1596305703433809920</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[jimmysea, oferecendo, apenas, amor, incondici...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1563947975923073025</td>\n",
       "      <td>[{'domain': {'id': '46', 'name': 'Business Tax...</td>\n",
       "      <td>2022-11-26 00:51:52+00:00</td>\n",
       "      <td>[1596305703248986113]</td>\n",
       "      <td>{'annotations': [{'start': 56, 'end': 65, 'pro...</td>\n",
       "      <td></td>\n",
       "      <td>1596305703248986113</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[saber, talvez, vou, morrer, nunca, ir, show, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1579194640380592130</td>\n",
       "      <td></td>\n",
       "      <td>2022-11-26 00:51:51+00:00</td>\n",
       "      <td>[1596305698685480960]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1596305698685480960</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[cupido, deve, ter, cometido, suicidio, nn, po...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author_id                                context_annotations  \\\n",
       "0  0  1486803274338643977  [{'domain': {'id': '46', 'name': 'Business Tax...   \n",
       "1  1  1438560931399835651                                                      \n",
       "2  2  1318048828797444098                                                      \n",
       "3  3  1563947975923073025  [{'domain': {'id': '46', 'name': 'Business Tax...   \n",
       "4  4  1579194640380592130                                                      \n",
       "\n",
       "                 created_at edit_history_tweet_ids  \\\n",
       "0 2022-11-26 00:51:56+00:00  [1596305720626262016]   \n",
       "1 2022-11-26 00:51:52+00:00  [1596305703991271424]   \n",
       "2 2022-11-26 00:51:52+00:00  [1596305703433809920]   \n",
       "3 2022-11-26 00:51:52+00:00  [1596305703248986113]   \n",
       "4 2022-11-26 00:51:51+00:00  [1596305698685480960]   \n",
       "\n",
       "                                            entities geo                   id  \\\n",
       "0                                                         1596305720626262016   \n",
       "1  {'annotations': [{'start': 0, 'end': 6, 'proba...      1596305703991271424   \n",
       "2                                                         1596305703433809920   \n",
       "3  {'annotations': [{'start': 56, 'end': 65, 'pro...      1596305703248986113   \n",
       "4                                                         1596305698685480960   \n",
       "\n",
       "  lang               source  \\\n",
       "0   pt  Twitter for Android   \n",
       "1   pt  Twitter for Android   \n",
       "2   pt  Twitter for Android   \n",
       "3   pt   Twitter for iPhone   \n",
       "4   pt   Twitter for iPhone   \n",
       "\n",
       "                                                text    y  \n",
       "0     [krlh, anime, romance, deixa, depressao, poha]  0.0  \n",
       "1  [cafalho, so, depressao, nessa, desgraca, vai,...  1.0  \n",
       "2  [jimmysea, oferecendo, apenas, amor, incondici...  0.0  \n",
       "3  [saber, talvez, vou, morrer, nunca, ir, show, ...  0.0  \n",
       "4  [cupido, deve, ter, cometido, suicidio, nn, po...  0.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
